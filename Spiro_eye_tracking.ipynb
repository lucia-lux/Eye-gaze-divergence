{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of eye tracking files from Spiro study.\n",
    "Gaze dispersion metric based on Christoforou et al, 2015: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4428128/pdf/fpsyg-06-00579.pdf\n",
    "The objective is as follows:\n",
    "(1) compute within-subject dispersion metric, based on short sections of the film (250 ms with 50 ms shift, ie 80% overlap)\n",
    "(2) get sections with extreme dispersion score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse film data, v3 Oct/Nov 2020\n",
    "\n",
    "# read and prep Tobii .tsv files from CortEx study\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import nanmedian, nanmean, nanstd\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def prepare_segment(x_gaze,y_gaze,start_num, stop_num):\n",
    "    #Scene1\n",
    "    dfx_scene = x_gaze[start_num:stop_num]\n",
    "    dfy_scene = y_gaze[start_num:stop_num]\n",
    "\n",
    "    # get rid of nans\n",
    "    nan_dfx = dfx_scene.where(dfx_scene>0,0)\n",
    "    nan_dfx = nan_dfx.where(nan_dfx<1280,0)\n",
    "    nan_dfy = dfy_scene.where(dfy_scene>0,0)\n",
    "    nan_dfy = nan_dfy.where(nan_dfy<1024,0)\n",
    "    x_m = nan_dfx.where(nan_dfx==0,1)\n",
    "    y_m = nan_dfy.where(nan_dfy==0,1)\n",
    "#    mask_dfx = nan_dfx.replace(x_m,1)\n",
    "#    mask_dfy = nan_dfy.replace(y_m,1)\n",
    "\n",
    "    dfx_scene = nan_dfx*y_m\n",
    "    dfy_scene = nan_dfy*x_m\n",
    "    return dfx_scene, dfy_scene\n",
    "\n",
    "def score_scenes(x_scene, y_scene):\n",
    "    scene_scores = []\n",
    "    # concatentate x and y values:\n",
    "    for k in range(len(x_scene)):\n",
    "        concat_ps = pd.concat([x_scene.iloc[k,:],y_scene.iloc[k,:]],axis = 1)\n",
    "        dist_ps = distance.pdist(concat_ps, metric = 'euclidean')\n",
    "        comp_ps = []\n",
    "        for l in range(len(dist_ps)):\n",
    "            score_ps = np.nansum(dist_ps[l])/len(concat_ps)\n",
    "            comp_ps.append(score_ps)\n",
    "        tot_score = sum(comp_ps)/len(concat_ps)\n",
    "        scene_scores.append(tot_score)\n",
    "    return comp_ps,scene_scores\n",
    "# get participant numbers\n",
    "\n",
    "def get_pnums(infiles):\n",
    "    \"\"\"\n",
    "    Get participant numbers from filenames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infiles: array of input file names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of participant numbers \n",
    "    \"\"\"\n",
    "    id = []\n",
    "    for i,filenames in enumerate(infiles):\n",
    "        pnum = [int(s) for s in filenames.split('_') if s.isdigit()]\n",
    "        id.append([pnum])\n",
    "\n",
    "def flatten(list_name):\n",
    "    \"\"\" \n",
    "    Function that flattens list of lists.\n",
    "    Source: https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-a-list-of-lists\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_name: str\n",
    "        Name of the list to flatten\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Flattened list\n",
    "    \"\"\"\n",
    "    flattened = [item for sublist in list_name for item in sublist]\n",
    "    return flattened\n",
    "\n",
    "\n",
    "\n",
    "def get_random_samps(df, frame_num_max, id):\n",
    "    \"\"\" \n",
    "    Fit a participant's gaze data to normal distribution.\n",
    "    Randomly sample normal distribution with participant-specific mean and std.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        dataframe holding eye tracking data from all participants\n",
    "\n",
    "    frame_num_max: int\n",
    "        maximum number of frames for participant, will be used to determine how many samples to draw\n",
    "\n",
    "    id: int\n",
    "        participant id \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Simulated gaze data in x and y.\n",
    "\n",
    "    \"\"\"\n",
    "    # first, let's simulate some gaze data.\n",
    "    # some basic parameters\n",
    "    #gaze_length = df.frame_num.max() # number of samples we need to generate\n",
    "    mux,stdx = norm.fit(df.loc[df.id == id,'gaze_in_x'])\n",
    "    muy,stdy = norm.fit(df.loc[df.id == id, 'gaze_in_y'])\n",
    "    # get samples\n",
    "    sim_in_x = norm.rvs(loc = mux, scale = stdx, size = frame_num_max)\n",
    "    sim_in_y = norm.rvs(loc = muy, scale = stdy, size = frame_num_max)\n",
    "    return sim_in_x, sim_in_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tobii_file:\n",
    "    def __init__(self, filename, film_dur_s, screenres_x = None, screenres_y = None, s_rate= None):\n",
    "        \"\"\"\n",
    "    \n",
    "        \"\"\"\n",
    "        if not screenres_x:\n",
    "            self.screen_resx = 1280\n",
    "        if not screenres_y:\n",
    "            self.screen_resy = 1024\n",
    "        if not s_rate:\n",
    "            s_rate = 60\n",
    "        self.filename = filename\n",
    "        self.screen_res = [screenres_x, screenres_y]\n",
    "        self.s_rate = s_rate\n",
    "        self.film_dur_s = film_dur_s\n",
    "        self.pnum = [int(s) for s in filename.split('_') if s.isdigit()]\n",
    "\n",
    "    def get_calibration(self, calibration_filename, calibration_dir):\n",
    "        \"\"\"\n",
    "        Get calibration details (accuracy, precision).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            Calibration filename\n",
    "        calibration file directory: str\n",
    "            path to calibration file directory\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        self.calibration_filename = calibration_filename\n",
    "        calibration_df = pd.read_csv(os.path.join(calibration_dir,calibration_filename))\n",
    "        if calibration_df.loc[calibration_df['used']=='used','used'].empty:\n",
    "            self.calibration = 'unused'\n",
    "        else:\n",
    "            self.calibration = calibration_df.loc[calibration_df['used'] == 'used',:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) get time stamps from message file\n",
    "- discard everything but the messages containing frame nr.\n",
    "(ii) load data file and add column for frame nr\n",
    "(iii) label rows between message (framenr) time stamps with the appropriate frame nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to establish where to find the files and read them in.\n",
    "rawfilepath = r\"P:\\Spironolactone\\eye_tracking\\Tobii\"\n",
    "# get merged Tobii files - these have both event info and eye gaze data.\n",
    "Tobii_files = [f for f in os.listdir(rawfilepath) if 'merged' in f]\n",
    "# get_calibration files\n",
    "calibration_files = [f for f in os.listdir(rawfilepath) if 'calib' in f and f.endswith('.tsv')]\n",
    "msg_files = [f for f in os.listdir(rawfilepath) if 'msg' in f and f.endswith('.tsv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pnum, left/right gaze point on display area, event messages \n",
    "# keep only columns between framenum 0 and the last frame\n",
    "# set invalid samples to NaN (validity == 0)\n",
    "frames = []\n",
    "gaze_in_x = []\n",
    "gaze_in_y = []\n",
    "pnums = []\n",
    "\n",
    "for i,filename in enumerate(Tobii_files):\n",
    "    # read file\n",
    "    tobii_file = pd.read_table(os.path.join(rawfilepath, filename))\n",
    "    # get participant number and add as column\n",
    "    tobii_file['pnum'] = np.repeat([int(s) for s in filename.split('_') if s.isdigit()], tobii_file.shape[0])\n",
    "    # get row index of frame each frame presentation\n",
    "    event_index = tobii_file.loc[tobii_file.msg.str.contains('FRAME',na = False),'msg'].index\n",
    "    # drop everything before first frame index (ie frame 0) and after last frame\n",
    "    tobii_file = tobii_file.loc[event_index[0]:event_index[-1],:]\n",
    "    # extract frame number\n",
    "    tobii_file.loc[event_index, 'msg'] = [f[0] for f in tobii_file.loc[event_index,'msg'].str.split(';', n = 1)]\n",
    "    tobii_file['frame_num'] = tobii_file.loc[event_index,'msg'].apply(lambda x: re.findall(r'\\d',x)).apply(''.join).astype('int')\n",
    "    # fill the rows between event markers with the appropriate frame number\n",
    "    tobii_file.loc[:,'frame_num'] = tobii_file.loc[:,'frame_num'].fillna(method = 'ffill')\n",
    "    # drop event markers\n",
    "    tobii_file = tobii_file.drop(labels = event_index,axis = 0)\n",
    "    # discard invalid samples\n",
    "    tobii_file = tobii_file.loc[(tobii_file.right_gaze_point_validity == 1)&(tobii_file.left_gaze_point_validity == 1),:]\n",
    "    # group by frame number and calculate mean\n",
    "    tobii_file = tobii_file.groupby('frame_num').mean()\n",
    "    tobii_file = tobii_file.reset_index()\n",
    "    # collect data into lists\n",
    "    pnums.append(tobii_file.pnum.values)\n",
    "    gaze_in_x.append(tobii_file.right_gaze_point_on_display_area_x.values)\n",
    "    gaze_in_y.append(tobii_file.left_gaze_point_on_display_area_y.values)\n",
    "    frames.append(tobii_file.frame_num.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create one big dataframe from the above.\n",
    "This is already ~ half a million rows for only 24 participants (with max 1 row per frame). This is going to become unwieldy for a significantly larger number of participants...may need to think about restructuring/parallel computing/cloud use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "et_df = pd.DataFrame({'id':flatten(pnums),'gaze_in_x':flatten(gaze_in_x),'gaze_in_y':flatten(gaze_in_y),'frame_num':flatten(frames)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have valid data for left/right gaze positions (on display area) for all participants in a single data frame. We now want to get a measure of divergence. We need to bear in mind a couple of things.\n",
    "First of all, calibration accuracy/precision will be different between participants. The first thing to check is to make sure that the precision is roughly the same. If not, this could really affect the divergence measure in a fairly unpredictable way, so we would need to exclude those subjects. Next, we want to have a look at accuracy. This is less of an issue because it is basically just an offset. We could try to correct gaze point data for each participant, but this will not be needed as divergent frames are identified based on comparing to a 'random' sequence of gaze data (which we will simulate below). Unless the offset is extreme, this should therefore not affect the results.\n",
    "Because different participants are missing different frames and because we don't expect huge variation between individual frames, given a frame rate of ~30 fps, we will look at 250 ms windows, and we will use a sliding window approach, shifting the window 50 ms each time (resulting in 80% overlap between windows).\n",
    "For each window and participant, we will calculate the Euclidean distance between the participant in question and every other participant/the participant in question and the random sequence. For any given window, we will then check whether this distance is greater in the former case than in the latter. If so, the window is identified as 'divergent' for that participant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's simulate x/y data by sampling from a normal distribution, based on each participant's gaze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 ms ± 2.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# create columns to hold simulated values\n",
    "et_df['gaze_in_x_sim'] = np.nan\n",
    "et_df['gaze_in_y_sim'] = np.nan\n",
    "\n",
    "# fill with simulated gaze data in x and y for each participant\n",
    "for i,pnum in enumerate(et_df.id.unique()):\n",
    "    pnum_df = et_df.loc[et_df.id == pnum,['id','gaze_in_x','gaze_in_y']]\n",
    "    max_frame = pnum_df.shape[0]\n",
    "    simx,simy = get_random_samps(pnum_df,max_frame,pnum)\n",
    "    et_df.loc[et_df.id == pnum, 'gaze_in_x_sim'] = simx\n",
    "    et_df.loc[et_df.id == pnum, 'gaze_in_y_sim'] = simy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to recreate 250 ms windows with a 50 ms shift, then we need to look at 15 samples at a time, and shift by 3\n",
    "# get max number of windows\n",
    "#stop_ind = et_df.frame_num.max()-15\n",
    "\n",
    "#for i in(np.arange(0,stop_ind,3)):\n",
    "    \n",
    "\n",
    "# for each window and participant, first figure out the percentage of missing data in a given window.\n",
    "# if >10%, set NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# first, let's construct a dataframe for the x and y gaze positions that holds data from all participants.\n",
    "gaze_x = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_x')\n",
    "gaze_y = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_y')\n",
    "gaze_x_sim = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_x_sim')\n",
    "gaze_y_sim = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_y_sim')\n",
    "\n",
    "for i, pnum in enumerate(et_df.id.unique()):\n",
    "    frame_act = pd.DataFrame({'x':gaze_x.loc[:,pnum], 'y':gaze_y.loc[:,pnum]})\n",
    "#et_df.loc[:,['frame_num','gaze_in_x','gaze_in_y']].groupby('frame_num').rolling(window = 15, min_periods = 3).apply(distance.euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.470329</td>\n",
       "      <td>0.518831</td>\n",
       "      <td>0.501687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491041</td>\n",
       "      <td>0.472667</td>\n",
       "      <td>0.509080</td>\n",
       "      <td>0.709627</td>\n",
       "      <td>0.682568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>0.511570</td>\n",
       "      <td>0.534296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.532877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515072</td>\n",
       "      <td>0.541451</td>\n",
       "      <td>0.528649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.564896</td>\n",
       "      <td>0.527396</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485849</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.510573</td>\n",
       "      <td>0.718187</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956490</td>\n",
       "      <td>0.541580</td>\n",
       "      <td>0.546304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519624</td>\n",
       "      <td>0.542194</td>\n",
       "      <td>0.565981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.478805</td>\n",
       "      <td>0.523807</td>\n",
       "      <td>0.504027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489227</td>\n",
       "      <td>0.470017</td>\n",
       "      <td>0.511068</td>\n",
       "      <td>0.701729</td>\n",
       "      <td>0.683303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925161</td>\n",
       "      <td>0.556362</td>\n",
       "      <td>0.535093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520258</td>\n",
       "      <td>0.536387</td>\n",
       "      <td>0.593265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.447756</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.504930</td>\n",
       "      <td>0.533887</td>\n",
       "      <td>0.485558</td>\n",
       "      <td>0.470927</td>\n",
       "      <td>0.512056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549584</td>\n",
       "      <td>0.544182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.518806</td>\n",
       "      <td>0.540277</td>\n",
       "      <td>0.594708</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.482590</td>\n",
       "      <td>0.518729</td>\n",
       "      <td>0.501289</td>\n",
       "      <td>0.520385</td>\n",
       "      <td>0.487901</td>\n",
       "      <td>0.468066</td>\n",
       "      <td>0.510920</td>\n",
       "      <td>0.614341</td>\n",
       "      <td>0.681754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546567</td>\n",
       "      <td>0.537078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.532966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523836</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>0.567019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24744.0</th>\n",
       "      <td>0.485601</td>\n",
       "      <td>0.538325</td>\n",
       "      <td>0.530856</td>\n",
       "      <td>0.452097</td>\n",
       "      <td>0.424921</td>\n",
       "      <td>0.440020</td>\n",
       "      <td>0.527678</td>\n",
       "      <td>0.695945</td>\n",
       "      <td>0.604979</td>\n",
       "      <td>0.534278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507252</td>\n",
       "      <td>0.468647</td>\n",
       "      <td>0.490312</td>\n",
       "      <td>0.496327</td>\n",
       "      <td>0.482349</td>\n",
       "      <td>0.496616</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.524720</td>\n",
       "      <td>0.322521</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24745.0</th>\n",
       "      <td>0.485444</td>\n",
       "      <td>0.534574</td>\n",
       "      <td>0.529286</td>\n",
       "      <td>0.450701</td>\n",
       "      <td>0.440218</td>\n",
       "      <td>0.444028</td>\n",
       "      <td>0.521384</td>\n",
       "      <td>0.695466</td>\n",
       "      <td>0.604251</td>\n",
       "      <td>0.526230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501755</td>\n",
       "      <td>0.474360</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.493653</td>\n",
       "      <td>0.481731</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.499571</td>\n",
       "      <td>0.514646</td>\n",
       "      <td>0.328214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24746.0</th>\n",
       "      <td>0.496992</td>\n",
       "      <td>0.537616</td>\n",
       "      <td>0.528466</td>\n",
       "      <td>0.453763</td>\n",
       "      <td>0.430738</td>\n",
       "      <td>0.444538</td>\n",
       "      <td>0.529510</td>\n",
       "      <td>0.697995</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>0.531610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493240</td>\n",
       "      <td>0.476332</td>\n",
       "      <td>0.487245</td>\n",
       "      <td>0.502314</td>\n",
       "      <td>0.481616</td>\n",
       "      <td>0.500057</td>\n",
       "      <td>0.502699</td>\n",
       "      <td>0.516043</td>\n",
       "      <td>0.325097</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24747.0</th>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.537064</td>\n",
       "      <td>0.529382</td>\n",
       "      <td>0.456095</td>\n",
       "      <td>0.438591</td>\n",
       "      <td>0.442055</td>\n",
       "      <td>0.518159</td>\n",
       "      <td>0.700697</td>\n",
       "      <td>0.600067</td>\n",
       "      <td>0.519275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505096</td>\n",
       "      <td>0.471270</td>\n",
       "      <td>0.472297</td>\n",
       "      <td>0.509348</td>\n",
       "      <td>0.484370</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>0.515221</td>\n",
       "      <td>0.327979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24748.0</th>\n",
       "      <td>0.502765</td>\n",
       "      <td>0.539358</td>\n",
       "      <td>0.529357</td>\n",
       "      <td>0.376769</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>0.440866</td>\n",
       "      <td>0.524024</td>\n",
       "      <td>0.697536</td>\n",
       "      <td>0.599324</td>\n",
       "      <td>0.520514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507911</td>\n",
       "      <td>0.465540</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.512271</td>\n",
       "      <td>0.485907</td>\n",
       "      <td>0.503199</td>\n",
       "      <td>0.497439</td>\n",
       "      <td>0.520890</td>\n",
       "      <td>0.331229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24749 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id               1         2         3         4         5         6   \\\n",
       "frame_num                                                               \n",
       "0.0        0.470329  0.518831  0.501687       NaN  0.491041  0.472667   \n",
       "1.0        0.564896  0.527396  0.499992       NaN  0.485849  0.469331   \n",
       "2.0        0.478805  0.523807  0.504027       NaN  0.489227  0.470017   \n",
       "3.0        0.447756  0.521365  0.504930  0.533887  0.485558  0.470927   \n",
       "4.0        0.482590  0.518729  0.501289  0.520385  0.487901  0.468066   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "24744.0    0.485601  0.538325  0.530856  0.452097  0.424921  0.440020   \n",
       "24745.0    0.485444  0.534574  0.529286  0.450701  0.440218  0.444028   \n",
       "24746.0    0.496992  0.537616  0.528466  0.453763  0.430738  0.444538   \n",
       "24747.0    0.495039  0.537064  0.529382  0.456095  0.438591  0.442055   \n",
       "24748.0    0.502765  0.539358  0.529357  0.376769  0.435074  0.440866   \n",
       "\n",
       "id               7         8         9         10  ...        15        16  \\\n",
       "frame_num                                          ...                       \n",
       "0.0        0.509080  0.709627  0.682568       NaN  ...  0.972367  0.511570   \n",
       "1.0        0.510573  0.718187  0.682286       NaN  ...  0.956490  0.541580   \n",
       "2.0        0.511068  0.701729  0.683303       NaN  ...  0.925161  0.556362   \n",
       "3.0        0.512056       NaN  0.678651       NaN  ...       NaN  0.549584   \n",
       "4.0        0.510920  0.614341  0.681754       NaN  ...       NaN  0.546567   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "24744.0    0.527678  0.695945  0.604979  0.534278  ...  0.507252  0.468647   \n",
       "24745.0    0.521384  0.695466  0.604251  0.526230  ...  0.501755  0.474360   \n",
       "24746.0    0.529510  0.697995  0.601344  0.531610  ...  0.493240  0.476332   \n",
       "24747.0    0.518159  0.700697  0.600067  0.519275  ...  0.505096  0.471270   \n",
       "24748.0    0.524024  0.697536  0.599324  0.520514  ...  0.507911  0.465540   \n",
       "\n",
       "id               17        18        20        21        23        24  \\\n",
       "frame_num                                                               \n",
       "0.0        0.534296       NaN  0.532877       NaN  0.515072  0.541451   \n",
       "1.0        0.546304       NaN  0.540626       NaN  0.519624  0.542194   \n",
       "2.0        0.535093       NaN  0.537728       NaN  0.520258  0.536387   \n",
       "3.0        0.544182       NaN  0.535042       NaN  0.518806  0.540277   \n",
       "4.0        0.537078       NaN  0.532966       NaN  0.523836  0.539729   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "24744.0    0.490312  0.496327  0.482349  0.496616  0.499997  0.524720   \n",
       "24745.0    0.486934  0.493653  0.481731  0.495913  0.499571  0.514646   \n",
       "24746.0    0.487245  0.502314  0.481616  0.500057  0.502699  0.516043   \n",
       "24747.0    0.472297  0.509348  0.484370  0.499030  0.500089  0.515221   \n",
       "24748.0    0.470085  0.512271  0.485907  0.503199  0.497439  0.520890   \n",
       "\n",
       "id               25  26  \n",
       "frame_num                \n",
       "0.0        0.528649 NaN  \n",
       "1.0        0.565981 NaN  \n",
       "2.0        0.593265 NaN  \n",
       "3.0        0.594708 NaN  \n",
       "4.0        0.567019 NaN  \n",
       "...             ...  ..  \n",
       "24744.0    0.322521 NaN  \n",
       "24745.0    0.328214 NaN  \n",
       "24746.0    0.325097 NaN  \n",
       "24747.0    0.327979 NaN  \n",
       "24748.0    0.331229 NaN  \n",
       "\n",
       "[24749 rows x 24 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaze_y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
