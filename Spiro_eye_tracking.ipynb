{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of eye tracking files from Spiro study.\n",
    "Gaze dispersion metric based on Christoforou et al, 2015: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4428128/pdf/fpsyg-06-00579.pdf\n",
    "The objective is as follows:\n",
    "(1) compute within-subject dispersion metric, based on short sections of the film (250 ms with 50 ms shift, ie 80% overlap)\n",
    "(2) get sections with extreme dispersion score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse film data, v3 Oct/Nov 2020\n",
    "\n",
    "# read and prep Tobii .tsv files from CortEx study\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import nanmedian, nanmean, nanstd\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from functools import cache\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# get participant numbers\n",
    "\n",
    "def get_pnums(infiles):\n",
    "    \"\"\"\n",
    "    Get participant numbers from filenames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infiles: array of input file names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of participant numbers \n",
    "    \"\"\"\n",
    "    id = []\n",
    "    for i,filenames in enumerate(infiles):\n",
    "        pnum = [int(s) for s in filenames.split('_') if s.isdigit()]\n",
    "        id.append([pnum])\n",
    "\n",
    "def flatten(list_name):\n",
    "    \"\"\" \n",
    "    Function that flattens list of lists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_name: str\n",
    "        Name of the list to flatten\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Flattened list\n",
    "    \"\"\"\n",
    "    flattened = [item for sublist in list_name for item in sublist]\n",
    "    return flattened\n",
    "\n",
    "def get_random_samps(df, frame_num_max, id):\n",
    "    \"\"\" \n",
    "    Fit a participant's gaze data to normal distribution.\n",
    "    Randomly sample normal distribution with participant-specific mean and std.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataframe\n",
    "        dataframe holding eye tracking data from all participants\n",
    "\n",
    "    frame_num_max: int\n",
    "        maximum number of frames for participant,\n",
    "        will be used to determine how many samples to draw\n",
    "\n",
    "    id: int\n",
    "        participant id \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Simulated gaze data in x and y.\n",
    "\n",
    "    \"\"\"\n",
    "    # first, let's simulate some gaze data.\n",
    "    # some basic parameters\n",
    "    #gaze_length = df.frame_num.max() # number of samples we need to generate\n",
    "    mux,stdx = norm.fit(df.loc[df.id == id,'gaze_in_x'])\n",
    "    muy,stdy = norm.fit(df.loc[df.id == id, 'gaze_in_y'])\n",
    "    # get samples\n",
    "    sim_in_x = norm.rvs(loc = mux, scale = stdx, size = frame_num_max)\n",
    "    sim_in_y = norm.rvs(loc = muy, scale = stdy, size = frame_num_max)\n",
    "    return sim_in_x, sim_in_y\n",
    "\n",
    "def calculate_dispersion_scores(frame_num, gaze_x, gaze_y,window_size, window_step):\n",
    "    \"\"\"\n",
    "    Calculate dispersion scores for each window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame_num: array of float\n",
    "        frame number\n",
    "    gaze_x, gaze_y: pandas DataFrame\n",
    "        gaze positions in x and y\n",
    "    window_size: int\n",
    "        size of window (how many frames)\n",
    "    window_step: int\n",
    "        number of frames to move each time the window slides\n",
    "        (ie overlap between windows)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list containing mean score per window\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    for i in frame_num:\n",
    "        frame_df = pd.concat([gaze_x.loc[i,:],gaze_y.loc[i,:]],axis = 1)\n",
    "        frame_dist_val =  np.unique(pairwise_distances(frame_df.dropna(),\n",
    "                            frame_df.dropna(),force_all_finite = True)).mean()\n",
    "        dists.append(frame_dist_val)\n",
    "\n",
    "     # now we calculate the mean euclidean distance for each window.\n",
    "    steps = np.arange(0,len(dists)-15,window_step)\n",
    "\n",
    "    # now calculate the mean for each 15-frame window (corresponds to ~250 ms)\n",
    "    # with a step size of 3 (80% overlap between successive windows)\n",
    "    wind_dists = []\n",
    "    for i in steps:\n",
    "        wind_dist = np.array(dists)[i:i+window_size].mean()\n",
    "        wind_dists.append(wind_dist)\n",
    "    wind_dists = pd.Series(wind_dists)\n",
    "    return wind_dists\n",
    "\n",
    "def get_consec_sections2(divergent_winds_numwinds):\n",
    "    \"\"\"\n",
    "    Find consecutive sections of divergent windows.\n",
    "    This should be faster than the other version.\n",
    "    Timeit says it's not.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    divergent_winds_numwinds: iterable\n",
    "        Iterable representing the window numbers\n",
    "        of windows identified as divergent\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of window numbers at which a break in \n",
    "    consecutive values was detected.\n",
    "    \"\"\"\n",
    "    index_break = [f for i,f in enumerate(divergent_winds_numwinds)\n",
    "                    if (i>0) & (f > divergent_winds_numwinds[i-1]+1)]\n",
    "\n",
    "    return index_break\n",
    "def get_consec_sections(divergent_winds_numwinds):\n",
    "    \"\"\"\n",
    "    Find consecutive sections of divergent windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    divergent_winds_numwinds: iterable\n",
    "        Iterable representing the window numbers\n",
    "        of windows identified as divergent\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of window numbers at which a break in \n",
    "    consecutive values was detected.\n",
    "\n",
    "    \"\"\"\n",
    "    index_break = []\n",
    "    for i,window in enumerate(divergent_winds_numwinds):\n",
    "        if i==0:\n",
    "            wind = window\n",
    "        elif (i>0) & (window-wind > 1):\n",
    "            index_break.append(window)\n",
    "            wind = window\n",
    "        else:\n",
    "            wind = window\n",
    "    \n",
    "    return index_break\n",
    "def get_frame_nums(index_break,step,wind):\n",
    "    \"\"\"\n",
    "    Get first and last frame for divergent windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index_break:   iterable\n",
    "        iterable containing start indices of each\n",
    "        non-consecutive batch of divergent windows\n",
    "        (I know, sorry)\n",
    "    step:   int\n",
    "        step size used for window calculation\n",
    "    wind:   int\n",
    "        number of frames in each window\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "    start/stop frame for each divergent section\n",
    "    \"\"\"\n",
    "    start_and_stop = list(zip(index_break[:-1], [i-1 for i in index_break[1:]]))\n",
    "    frame_nums = [(start*step+wind,stop*step+wind)\n",
    "                for start,stop in start_and_stop]\n",
    "\n",
    "    return frame_nums\n",
    "\n",
    "\n",
    "def calculate_iGDI(dispersion_scores, mean_sim_score):\n",
    "    \"\"\"\n",
    "    Calculate the eye gaze divergence index (iGDI)\n",
    "    Proportion of divergent windows across film viewings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dispersion_scores:  pd.Series\n",
    "        dispersion scores for each window\n",
    "    mean_sim_score: float\n",
    "        mean dispersion score across all\n",
    "        simulated windows\n",
    "\n",
    "    Returns\n",
    "    ------- \n",
    "    divergent_windows:\n",
    "        Binary array indicating whether a given window was\n",
    "        classed as divergent or not\n",
    "    \n",
    "    iGDI_score:\n",
    "        Proportion of windows classed as divergent\n",
    "        (ie eye gaze divergence index)\n",
    "\n",
    "    \"\"\"\n",
    "    divergent_windows = np.zeros(len(dispersion_scores))\n",
    "\n",
    "    for i,disp_score in enumerate(dispersion_scores):\n",
    "        if disp_score>mean_sim_score:\n",
    "            divergent_windows[i]=1\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    iGDI_score = sum(test)/len(dispersion_scores)\n",
    "    return iGDI_score, divergent_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tobii_file:\n",
    "    def __init__(self, filename, film_dur_s, screenres_x = None, screenres_y = None, s_rate= None):\n",
    "        \"\"\"\n",
    "    \n",
    "        \"\"\"\n",
    "        if not screenres_x:\n",
    "            self.screen_resx = 1280\n",
    "        if not screenres_y:\n",
    "            self.screen_resy = 1024\n",
    "        if not s_rate:\n",
    "            s_rate = 60\n",
    "        self.filename = filename\n",
    "        self.screen_res = [screenres_x, screenres_y]\n",
    "        self.s_rate = s_rate\n",
    "        self.film_dur_s = film_dur_s\n",
    "        self.pnum = [int(s) for s in filename.split('_') if s.isdigit()]\n",
    "\n",
    "    def get_calibration(self, calibration_filename, calibration_dir):\n",
    "        \"\"\"\n",
    "        Get calibration details (accuracy, precision).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: str\n",
    "            Calibration filename\n",
    "        calibration file directory: str\n",
    "            path to calibration file directory\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        self.calibration_filename = calibration_filename\n",
    "        calibration_df = pd.read_csv(os.path.join(calibration_dir,calibration_filename))\n",
    "        if calibration_df.loc[calibration_df['used']=='used','used'].empty:\n",
    "            self.calibration = 'unused'\n",
    "        else:\n",
    "            self.calibration = calibration_df.loc[calibration_df['used'] == 'used',:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) get time stamps from message file\n",
    "- discard everything but the messages containing frame nr.\n",
    "(ii) load data file and add column for frame nr\n",
    "(iii) label rows between message (framenr) time stamps with the appropriate frame nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 0\n",
    "if home:\n",
    "    rawfilepath = r\"C:\\Users\\Luzia T\\Eye-gaze-divergence\"\n",
    "    Tobii_files = [f for f in os.listdir(rawfilepath) if 'merged' in f]\n",
    "    calibration_files = [f for f in os.listdir(rawfilepath) if 'calib' in f]\n",
    "else:\n",
    "    # first we need to establish where to find the files and read them in.\n",
    "    rawfilepath = r\"P:\\Spironolactone\\eye_tracking\\Tobii\"\n",
    "    # get merged Tobii files - these have both event info and eye gaze data.\n",
    "    Tobii_files = [f for f in os.listdir(rawfilepath) if 'merged' in f]\n",
    "    # get_calibration files\n",
    "    calibration_files = [f for f in os.listdir(rawfilepath) if 'calib' in f and f.endswith('.tsv')]\n",
    "    msg_files = [f for f in os.listdir(rawfilepath) if 'msg' in f and f.endswith('.tsv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pnum, left/right gaze point on display area, event messages \n",
    "# keep only columns between framenum 0 and the last frame\n",
    "# set invalid samples to NaN (validity == 0)\n",
    "frames = []\n",
    "gaze_in_x = []\n",
    "gaze_in_y = []\n",
    "pnums = []\n",
    "\n",
    "for i,filename in enumerate(Tobii_files):\n",
    "    # read file\n",
    "    tobii_file = pd.read_table(os.path.join(rawfilepath, filename))\n",
    "    # get participant number and add as column\n",
    "    tobii_file['pnum'] = np.repeat([int(s) for s in filename.split('_') if s.isdigit()], tobii_file.shape[0])\n",
    "    # get row index of frame each frame presentation\n",
    "    event_index = tobii_file.loc[tobii_file.msg.str.contains('FRAME',na = False),'msg'].index\n",
    "    # drop everything before first frame index (ie frame 0) and after last frame\n",
    "    tobii_file = tobii_file.loc[event_index[0]:event_index[-1],:]\n",
    "    # extract frame number\n",
    "    tobii_file.loc[event_index, 'msg'] = [f[0] for f in tobii_file.loc[event_index,'msg'].str.split(';', n = 1)]\n",
    "    tobii_file['frame_num'] = tobii_file.loc[event_index,'msg'].apply(lambda x: re.findall(r'\\d',x)).apply(''.join).astype('int')\n",
    "    # fill the rows between event markers with the appropriate frame number\n",
    "    tobii_file.loc[:,'frame_num'] = tobii_file.loc[:,'frame_num'].fillna(method = 'ffill')\n",
    "    # drop event markers\n",
    "    tobii_file = tobii_file.drop(labels = event_index,axis = 0)\n",
    "    # discard invalid samples\n",
    "    tobii_file = tobii_file.loc[(tobii_file.right_gaze_point_validity == 1)&(tobii_file.left_gaze_point_validity == 1),:]\n",
    "    tobii_file = tobii_file.groupby('frame_num').mean()\n",
    "    tobii_file = tobii_file.reset_index()\n",
    "    # collect data into lists\n",
    "    pnums.append(tobii_file.pnum.values)\n",
    "    gaze_in_x.append(tobii_file.right_gaze_point_on_display_area_x.values)\n",
    "    gaze_in_y.append(tobii_file.left_gaze_point_on_display_area_y.values)\n",
    "    frames.append(tobii_file.frame_num.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create one big dataframe from the above.\n",
    "This is already ~ half a million rows for only 24 participants (with max 1 row per frame). This is going to become unwieldy for a significantly larger number of participants...may need to think about restructuring/parallel computing/cloud use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "et_df = pd.DataFrame({'id':flatten(pnums),'gaze_in_x':flatten(gaze_in_x),'gaze_in_y':flatten(gaze_in_y),'frame_num':flatten(frames)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have valid data for left/right gaze positions (on display area) for all participants in a single data frame. We now want to get a measure of divergence. We need to bear in mind a couple of things.\n",
    "First of all, calibration accuracy/precision will be different between participants. The first thing to check is to make sure that the precision is roughly the same. If not, this could really affect the divergence measure in a fairly unpredictable way, so we would need to exclude those subjects. Next, we want to have a look at accuracy. This is less of an issue because it is basically just an offset. We could try to correct gaze point data for each participant, but this will not be needed as divergent frames are identified based on comparing to a 'random' sequence of gaze data (which we will simulate below). Unless the offset is extreme, this should therefore not affect the results.\n",
    "Because different participants are missing different frames and because we don't expect huge variation between individual frames, given a frame rate of ~30 fps, we will look at 250 ms windows, and we will use a sliding window approach, shifting the window 50 ms each time (resulting in 80% overlap between windows).\n",
    "For each window and participant, we will calculate the Euclidean distance between the participant in question and every other participant/the participant in question and the random sequence. For any given window, we will then check whether this distance is greater in the former case than in the latter. If so, the window is identified as 'divergent' for that participant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's simulate x/y data by sampling from a normal distribution, based on each participant's gaze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# create columns to hold simulated values\n",
    "et_df['gaze_in_x_sim'] = np.nan\n",
    "et_df['gaze_in_y_sim'] = np.nan\n",
    "\n",
    "# fill with simulated gaze data in x and y for each participant\n",
    "for i,pnum in enumerate(et_df.id.unique()):\n",
    "    pnum_df = et_df.loc[et_df.id == pnum,['id','gaze_in_x','gaze_in_y']]\n",
    "    max_frame = pnum_df.shape[0]\n",
    "    simx,simy = get_random_samps(pnum_df,max_frame,pnum)\n",
    "    et_df.loc[et_df.id == pnum, 'gaze_in_x_sim'] = simx\n",
    "    et_df.loc[et_df.id == pnum, 'gaze_in_y_sim'] = simy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's construct a dataframe for the x and y gaze positions that holds data from all participants.\n",
    "gaze_x = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_x')\n",
    "gaze_y = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_y')\n",
    "gaze_x_sim = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_x_sim')\n",
    "gaze_y_sim = et_df.pivot(index = 'frame_num',columns = 'id', values = 'gaze_in_y_sim')\n",
    "\n",
    "# calculate dispersion scores for simulated and 'actual' gaze data.\n",
    "wind_dists_act = calculate_dispersion_scores(gaze_y.index, gaze_x,gaze_y, 15, 3)\n",
    "wind_dists_sim = calculate_dispersion_scores(gaze_y.index,gaze_x_sim,gaze_y_sim,15,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean divergence for simulated windows is 0.1737529933089151.\n",
      "The mean divergence for actual windows is 0.13059413046270418.\n",
      "The percentage of divergent windows is 12.783505154639174.\n"
     ]
    }
   ],
   "source": [
    "mean_dist_sim = wind_dists_sim.mean()\n",
    "iGDIs, divergent_winds = calculate_iGDI(wind_dists_act,mean_dist_sim)\n",
    "print('The mean divergence for simulated windows is {}.'.format(mean_dist_sim))\n",
    "print('The mean divergence for actual windows is {}.'.format(wind_dists_act.mean()))\n",
    "print('The percentage of divergent windows is {}.'.format(iGDIs*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_break = get_consec_sections2(wind_dists_act[wind_dists_act*divergent_winds>0].index)\n",
    "frame_nums = get_frame_nums(index_break, 3, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_frame_secs = [f[1]-f[0] for f in frame_nums]\n",
    "len_frame_secs.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_stills_dir = r\"C:\\Users\\luzia.troebinger\\CortEx\\film_stills\"\n",
    "stills = os.listdir(film_stills_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"P:\\Eye-gaze-divergence\\stills_start_end\"\n",
    "for i, frame in enumerate(frame_nums):                                                                         \n",
    "    img = Image.open(os.path.join(film_stills_dir, stills[frame[0]]))   \n",
    "    img.save(os.path.join(output_dir, ''.join(['sec_'+str(i)+'_start_frame.png'])))\n",
    "    img = Image.open(os.path.join(film_stills_dir, stills[frame[1]]))\n",
    "    img.save(os.path.join(output_dir, ''.join(['sec_'+str(i)+'_end_frame.png'])))\n",
    "    #img.show() \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
